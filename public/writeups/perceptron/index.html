<!DOCTYPE html>
<html lang="en" style="font-size: 105%">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <meta name="author" content="">

  
  
  <meta name="description" content="An implementation-focused walkthrough of the Perceptron and Pocket Learning Algorithms in R, using synthetic 2D data to explore linear classification, weight updates, and performance evaluation.">
  

  
  <link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313//images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313//images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313//images/favicon-16x16.png">

  
  
  <meta name="keywords" content='hugo latex theme blog texify texify2 texify3 michael neuper'>
  

  
  
  <link rel="stylesheet" href='/katex/katex.min.css'>
<script defer defer src='/katex/katex.min.js'></script>
<script defer src='/katex/contrib/auto-render.min.js'></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          throwOnError : false
        });
    });
</script>
  



  
  <meta property="og:url" content="http://localhost:1313/writeups/perceptron/">
  <meta property="og:site_name" content="Simran Tinani">
  <meta property="og:title" content="Perceptrons from Scratch: A Starting Point for Machine Learning">
  <meta property="og:description" content="An implementation-focused walkthrough of the Perceptron and Pocket Learning Algorithms in R, using synthetic 2D data to explore linear classification, weight updates, and performance evaluation.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="writeups">
    <meta property="article:published_time" content="2023-02-01T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-02-01T00:00:00+00:00">


  
  <link rel="canonical" href="http://localhost:1313/writeups/perceptron/">

  
  
  
  <meta itemprop="name" content="Perceptrons from Scratch: A Starting Point for Machine Learning">
  <meta itemprop="description" content="An implementation-focused walkthrough of the Perceptron and Pocket Learning Algorithms in R, using synthetic 2D data to explore linear classification, weight updates, and performance evaluation.">
  <meta itemprop="datePublished" content="2023-02-01T00:00:00+00:00">
  <meta itemprop="dateModified" content="2023-02-01T00:00:00+00:00">
  <meta itemprop="wordCount" content="1981">
  <meta itemprop="keywords" content="AI and Machine Learning">

  
  
  <title>Perceptrons from Scratch: A Starting Point for Machine Learning - </title>
  

  
  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Perceptrons from Scratch: A Starting Point for Machine Learning">
  <meta name="twitter:description" content="An implementation-focused walkthrough of the Perceptron and Pocket Learning Algorithms in R, using synthetic 2D data to explore linear classification, weight updates, and performance evaluation.">


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" integrity="sha512-dRgZyrTq+zMJq6dfypZ7V+1RWgZ5BkMiDwIXJ1PV4AmxzyozpmXT3RBizJFlMKX8Nfq1f1F5hOgFlAxu9kw6Yg==" crossorigin="anonymous" referrerpolicy="no-referrer" />

  
  <link href="https://fonts.googleapis.com/css2?family=Lora:wght@400;600&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Libre+Baskerville&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Cormorant+Garamond:wght@400;600&display=swap" rel="stylesheet">








  
  
    <link rel="stylesheet" href="/css/single.min.a70322a61e6d0900242309fe907aa7c6d09de1af6d54a5203810f320fc65aa58.css" integrity="sha256-pwMiph5tCQAkIwn&#43;kHqnxtCd4a9tVKUgOBDzIPxlqlg=" crossorigin="anonymous">
  








  <link rel="stylesheet" href="/css/common.min.cb988adfe659afb27f8185d06a1772ca1405f376e32f54ecb8cd63a2ca8b2552.css" integrity="sha256-y5iK3&#43;ZZr7J/gYXQahdyyhQF83bjL1TsuM1josqLJVI=" crossorigin="anonymous">





  <link rel="stylesheet" href="/css/content.min.ba38eba94cb47fef9936258c42d11ff19fa9686a30b38e783773fe3f15eb44dc.css" integrity="sha256-ujjrqUy0f&#43;&#43;ZNiWMQtEf8Z&#43;paGows454N3P&#43;PxXrRNw=" crossorigin="anonymous">





  <link rel="stylesheet" href="/css/custom.min.738f829e2e787ce7bdfe28053c21461ac08b70909965e55b2af0572277fef033.css" integrity="sha256-c4&#43;Cni54fOe9/igFPCFGGsCLcJCZZeVbKvBXInf&#43;8DM=" crossorigin="anonymous">







</head>

<body>
  <div id="wrapper">
    <header class="navbar-container">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="..." crossorigin="anonymous">

  <div class="signature">Simran Tinani</div>

  
  
  

  
  


  


  


  


  


  

  
    
    <nav class="navbar">
      <div class="nav-left">
        
          <a href="/">Home</a>
        
          <a href="/about/">About</a>
        
          <a href="/writeups/">Writeups</a>
        
          <a href="/research/">Research</a>
        
          <a href="https://github.com/simrantinani">GitHub</a>
        
      </div>
      <div class="nav-center inactive"><span>&nbsp;</span></div>
      <div class="nav-right"></div>
    </nav>
  
</header>

    
<main id="main" class="container mx-auto px-4">

  
  <article class="content numbered-subtitles">
    <h2 id="introduction">Introduction</h2>
<p>The Perceptron Learning Algorithm is one of the simplest machine learning algorithms and a crucial building block of more complex machine learning and deep learning models. A neural network is, in fact, known as a multi-layer perceptron (MLP), because (of course) it is composed of several layers of perceptrons stacked together. Apart from providing a glimpse into the working of a neural network, an understanding of a perceptron’s working is essential for a beginner to grasp the most fundamental concepts of machine learning. A simple modification of this algorithm is termed the Pocket Learning Algorithm. In this article, we will build the simple perceptron and the pocket learning algorithm from a scratch, and check their performance in classifying points in the 2-dimensional Euclidean plane into two halves. Minimal expertise in coding in R is assumed, and most of the code is self-explanatory.</p>
<h2 id="defining-the-training-space-and-target-function">Defining the Training Space and Target Function</h2>
<p>First define the limits of the space to work in during training: let $(x_1, y_1)$ and $(x_2, y_2)$ be the coordinates defining this rectangular subspace of the $XY$ plane. I have taken them to be $(-2,-2)$ and $(2,2)$ respectively. Note that “&lt;-” is the assignment operator in R.</p>
<pre tabindex="0"><code>x_1 &lt;- (-2)
y_1 &lt;- (-2)
x_2 &lt;- 2
y_2 &lt;- 2
</code></pre><p>We now wish to define the target function, which is, in our case, a straight line. We let this line be defined as the line passing through two random points in the training domain (the subspace defined by (x_1, y_1) and (x_2, y_2)).</p>
<pre tabindex="0"><code>x &lt;-  runif(2, min = x_1, max = x_2)
y &lt;- runif(2, min = y_1, max = y_2)
fit &lt;- (lm(y~x))
</code></pre><p>We now define our target function by extracting the coefficients of the fit.</p>
<pre tabindex="0"><code>t &lt;- summary(fit)$coefficients[,1]
f &lt;- function(x){
  t[2]*x + t[1] #(general line equation: y = slope*x + intercept)
}
</code></pre><h2 id="creating-the-training-dataset">Creating the Training Dataset</h2>
<p>Now we define the number of points from the training domain to be taken in the training set. I have taken this number to be $1000$. This number $N$ and the limits $x_1$, $x_2$, $y_1$, $y_2$ may be experimented with later. Then, we create and populate separate matrices for the training data points and their classification labels based on the line defined by function $f$.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="n">N</span> <span class="o">&lt;-</span> <span class="m">1000</span> <span class="c1"># Number of data points in the training set</span>
</span></span><span class="line"><span class="cl"><span class="n">A</span> <span class="o">&lt;-</span> <span class="nf">matrix</span><span class="p">(</span><span class="n">ncol</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="m">2</span><span class="p">)</span> <span class="c1"># N random points of the space</span>
</span></span><span class="line"><span class="cl"><span class="n">b</span> <span class="o">&lt;-</span> <span class="nf">matrix</span><span class="p">(</span><span class="n">ncol</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="m">1</span><span class="p">)</span> <span class="c1"># labels of the points in A: i.e. which                                                    #                             side of the line they lie on</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kr">for</span><span class="p">(</span><span class="n">i</span> <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="n">N</span><span class="p">){</span>
</span></span><span class="line"><span class="cl">  <span class="n">A[</span><span class="p">,</span> <span class="n">i]</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="nf">runif</span><span class="p">(</span><span class="m">2</span><span class="p">,</span> <span class="n">min</span> <span class="o">=</span> <span class="n">x_1</span><span class="p">,</span> <span class="n">max</span> <span class="o">=</span> <span class="n">x_2</span><span class="p">))</span> <span class="c1"># random entries in       #                                              the training domain</span>
</span></span><span class="line"><span class="cl">  <span class="n">b[1</span><span class="p">,</span> <span class="n">i]</span> <span class="o">&lt;-</span> <span class="nf">sign</span><span class="p">(</span><span class="n">A[2</span><span class="p">,</span> <span class="n">i]</span> <span class="o">-</span> <span class="nf">f</span><span class="p">(</span><span class="n">A[1</span><span class="p">,</span> <span class="n">i]</span><span class="p">))</span> <span class="c1"># whether the point in A[,i]                                           #                                         lies above or below the </span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Visualization</span>
</span></span><span class="line"><span class="cl"><span class="nf">plot</span><span class="p">(</span><span class="n">A[1</span><span class="p">,</span> <span class="n">]</span><span class="p">,</span> <span class="n">A[2</span><span class="p">,</span> <span class="n">]</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="nf">abline</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="s">&#34;red&#34;</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">k</span><span class="o">=</span><span class="nf">which</span><span class="p">(</span><span class="n">b</span><span class="o">==</span><span class="m">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">points</span><span class="p">(</span><span class="n">A[1</span><span class="p">,</span><span class="n">k]</span><span class="p">,</span> <span class="n">A[2</span><span class="p">,</span><span class="n">k]</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="s">&#34;blue&#34;</span><span class="p">)</span> <span class="c1"># points above the line are        #                                    labelled 1</span>
</span></span></code></pre></div><figure style="text-align: center; margin: 2em 0;">
  <img src="/images/perceptron.png" alt="An example plot showing linearly separable data" width="300" style="border: 1px solid #ccc; border-radius: 8px;">
  <figcaption style="font-size: 0.9em; color: #555; margin-top: 0.5em;">
    An example of the plots obtained
  </figcaption>
</figure>
<h2 id="perceptron-algorithm-initialization-and-updates">Perceptron Algorithm: Initialization and Updates</h2>
<p>The plot provides a neat visualization of what we have done so far. We have $1000$ points and a line predefined in a plane. Every point above the line is labelled 1 and every point below the line is labelled $-1$. Now assume that the functional form of the line is taken away from us, and we are only left with the points and their labels. We want a function $g$ that can approximate the classification of the line we had in the best way, on the entire XY plane. That is, we want a function that will separate the plane in a way as similar as possible to the original line, given only these $1000$ training points.</p>
<p>We do this by beginning with a random vector of coefficients, $w$, which defines our hypothesized line $g,$ checking its classification on the given points, and iteratively updating it in a way such that at each iteration, it does a better job at the classification of the points. Here, we have started with $w$ as a vector of zeroes.</p>
<pre tabindex="0"><code># Initialization

w &lt;- rep(0,3) # initial values in the weight vector
g &lt;- function(z){ # function g will attempt to approximate f            
 t(w) %*% z
}
</code></pre><h3 id="weight-update-rule-and-intuition">Weight Update Rule and Intuition</h3>
<p>At each step, a random point out of the $1000$ available training points is selected, and the hypothesis function defined by the vector $w$ is evaluated on the point. If the point $(x, y)$ with label $p$ is in the training set (here, $p \in {1, -1}$), and turns out to be classified wrongly by $w$ (i.e., $w$ predicts its label to be $-p$), $w$ is updated so that its new value equals $w + (x, y) \cdot p$. We do this for $2000$ steps (in general, $2 \cdot N$) to ensure that updating is done with a sufficient number of distinct training points.</p>
<p>At each step, this new $w$ is more likely to classify the same point correctly, because its prediction on the same point is now</p>
<p>$$
\text{sign}\left((w + (x, y) \cdot p)^T \cdot (x, y)\right) = \text{sign}\left(w^T \cdot (x, y) + p \cdot (x, y)^T \cdot (x, y)\right)
$$</p>
<p>where $T$ denotes the transpose of a vector and $\cdot$ denotes matrix multiplication. For someone unfamiliar with linear algebra, the notation simply means that the weights are being multiplied element-wise to the components of the point, and the sign of that product is giving the side of the line on which the point lies.</p>
<p>When $p = 1$, $\text{sign}(w^T \cdot (x, y))$ must be $-1$, since the point is assumed to be misclassified by $w$ (i.e., $g$). Adding a positive quantity, $p \cdot (x, y)^T \cdot (x, y)$, to it makes it more likely for the prediction by the new $w$ (thus $g$) to be correct.</p>
<p>When this process is repeated a sufficient number of times, a good percent of the training set points end up correctly classified, and the resulting weights/hypothesis function are then used to classify every point on the plane.</p>
<p>Also note that in the above discussion, $w$ is assumed to be a two-dimensional vector. However, $w$ needs an additional $1$ appended to its front, to account for the constant term in a 2D line’s equation $(a \cdot x + b \cdot y + c)$. This has been done in the code.</p>
<h2 id="pocket-learning-algorithm">Pocket Learning Algorithm</h2>
<p>Above, we have defined the Perceptron Learning algorithm. The Pocket Learning algorithm is a simple modification. Since the algorithm proceeds by updating the weights using a single point at each step, the overall accuracy on the training set might go down in a single update. In the pocket algorithm, instead of using the classification function obtained at the end of all iterations, one simultaneously calculates the training accuracy at each step, and stores the most accurate hypothesis function obtained from each past step. At the end, the hypothesis is the best possible that could be obtained from the training set with this algorithm.</p>
<pre tabindex="0"><code>w_pocket &lt;- w # Pocket (best) weight vector
training_accuracy&lt;-0 # at each iteration, this will be added to
pocket_accuracy&lt;-0 # the best achievable accuracy
i_pocket&lt;-0 # index at which pocket accuracy is achieved

i &lt;- 1

while(i &lt; 2*N+1){
  j = sample(1:N, 1)
  if((sign(g(c(1, A[, j]))) == b[1, j]) == 0){ 
    # update the weight vector at each misclassified point
    w &lt;- w + b[1, j]*c(1, A[, j])
  }
  training_accuracy&lt;-c(training_accuracy,0)
  for(k in 1:N){
    if(sign(g(c(1, A[,k ]))) == b[, k]){
      training_accuracy[length(training_accuracy)] &lt;- training_accuracy[length(training_accuracy)] + 1/N
    }
  }
  if(tail(training_accuracy,1)&gt;max(head(training_accuracy,-1))){
    w_pocket&lt;-w
    i_pocket&lt;-i
    pocket_accuracy&lt;- tail(training_accuracy,1)
  }
  i = i + 1
}

final_training_accuracy &lt;- tail(training_accuracy,1) 
# training accuracy at the last iteration
</code></pre><h2 id="evaluating-test-accuracy">Evaluating Test Accuracy</h2>
<p>We have calculated both training accuracies. It is now time to calculate test accuracies. Since the test set is a continuous space, we cannot evaluate the exact classification accuracy, we can only estimate it by taking a large random sample of discrete points from the entire space. Here, we take 100,000 such points. We also want the domain to be much larger than the training domain, and so we take the test limits to be 100 multiplied by the old training limits.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="c1"># Preparing a larger sample data set to approximate test accuracy</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">S</span> <span class="o">&lt;-</span> <span class="nf">matrix</span><span class="p">(</span><span class="n">ncol</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="m">100</span><span class="p">),</span> <span class="n">nrow</span><span class="o">=</span><span class="m">2</span><span class="p">)</span> <span class="c1"># matrix with 10000 random entries</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kr">for</span><span class="p">(</span><span class="n">v</span> <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="m">100</span><span class="p">)){</span>
</span></span><span class="line"><span class="cl"> <span class="n">S[</span><span class="p">,</span> <span class="n">v]</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="nf">runif</span><span class="p">(</span><span class="m">2</span><span class="p">,</span> <span class="n">min</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span><span class="n">y1</span><span class="p">)</span><span class="o">*</span><span class="m">100</span><span class="p">,</span> <span class="n">max</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span><span class="n">y2</span><span class="p">)</span><span class="o">*</span><span class="m">100</span><span class="p">))</span> 
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Simple Perceptron</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">test_accuracy</span> <span class="o">&lt;-</span><span class="m">0</span>
</span></span><span class="line"><span class="cl"><span class="n">v</span> <span class="o">&lt;-</span> <span class="m">1</span>
</span></span><span class="line"><span class="cl"><span class="kr">while</span><span class="p">(</span><span class="n">v</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="nf">ncol</span><span class="p">(</span><span class="n">S</span><span class="p">))){</span> 
</span></span><span class="line"><span class="cl"> <span class="kr">if</span><span class="p">(</span><span class="nf">sign</span><span class="p">(</span><span class="nf">g</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="n">S[</span><span class="p">,</span> <span class="n">v]</span><span class="p">)))</span> <span class="o">==</span> <span class="nf">sign</span><span class="p">(</span><span class="n">S[</span><span class="p">,</span> <span class="n">v][2]</span> — <span class="nf">f</span><span class="p">(</span><span class="n">S[</span><span class="p">,</span> <span class="n">v][1]</span><span class="p">))){</span>
</span></span><span class="line"><span class="cl"> <span class="n">test_accuracy</span> <span class="o">&lt;-</span> <span class="n">test_accuracy</span> <span class="o">+</span> <span class="m">1</span><span class="o">/</span><span class="nf">ncol</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"> <span class="p">}</span>
</span></span><span class="line"><span class="cl"> <span class="n">v</span> <span class="o">&lt;-</span> <span class="n">v</span> <span class="o">+</span> <span class="m">1</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Pocket Learning Algorithm</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">pocket_test_accuracy</span> <span class="o">&lt;-</span><span class="m">0</span>
</span></span><span class="line"><span class="cl"><span class="n">v</span> <span class="o">&lt;-</span> <span class="m">1</span>
</span></span><span class="line"><span class="cl"><span class="n">g_pocket</span> <span class="o">&lt;-</span> <span class="kr">function</span><span class="p">(</span><span class="n">z</span><span class="p">){</span> <span class="c1"># function g_pocket multiplies by w_pocket</span>
</span></span><span class="line"><span class="cl"> <span class="nf">t</span><span class="p">(</span><span class="n">w_pocket</span><span class="p">)</span> <span class="o">%*%</span> <span class="n">z</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kr">while</span><span class="p">(</span><span class="n">v</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="nf">ncol</span><span class="p">(</span><span class="n">S</span><span class="p">))){</span> 
</span></span><span class="line"><span class="cl"> <span class="kr">if</span><span class="p">(</span><span class="nf">sign</span><span class="p">(</span><span class="nf">g_pocket</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="n">S[</span><span class="p">,</span> <span class="n">v]</span><span class="p">)))</span> <span class="o">==</span> <span class="nf">sign</span><span class="p">(</span><span class="n">S[</span><span class="p">,</span> <span class="n">v][2]</span> — <span class="nf">f</span><span class="p">(</span><span class="n">S[</span><span class="p">,</span> <span class="n">v][1]</span><span class="p">))){</span>
</span></span><span class="line"><span class="cl"> <span class="n">pocket_test_accuracy</span> <span class="o">&lt;-</span> <span class="n">pocket_test_accuracy</span> <span class="o">+</span> <span class="m">1</span><span class="o">/</span><span class="nf">ncol</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"> <span class="p">}</span>
</span></span><span class="line"><span class="cl"> <span class="n">v</span> <span class="o">&lt;-</span> <span class="n">v</span> <span class="o">+</span> <span class="m">1</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>All the calculations are now complete, and we may display our results in terms of percentages.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="nf">print</span><span class="p">(</span><span class="n">i_pocket</span><span class="p">)</span> <span class="c1"># at i_pocket, training accuracy stopped increasing</span>
</span></span><span class="line"><span class="cl"><span class="nf">print</span><span class="p">(</span><span class="n">final_training_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> <span class="c1"># Perceptron training accuracy</span>
</span></span><span class="line"><span class="cl"><span class="nf">print</span><span class="p">(</span><span class="n">pocket_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> <span class="c1"># Pocket training accuracy</span>
</span></span><span class="line"><span class="cl"><span class="nf">print</span><span class="p">(</span><span class="n">test_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> <span class="c1"># Perceptron test accuracy</span>
</span></span><span class="line"><span class="cl"><span class="nf">print</span><span class="p">(</span><span class="n">pocket_test_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> <span class="c1"># Pocket test accuracy</span>
</span></span></code></pre></div><h2 id="experimental-results">Experimental Results</h2>
<p>In many cases, the pocket and perceptron algorithms yield the same results. This corresponds to the case where the last iteration step yields the highest accuracy among all. In others, the perceptron yields lower training and test results than the pocket algorithm. Examples of both these types of results yielded by a run of the entire code follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="c1"># Run 1</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">i_pocket</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="m">528</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">final_training_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="m">96</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">pocket_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="m">98.4</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">test_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="m">95.24</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">pocket_test_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="m">97.82</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="c1"># Run 2</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">i_pocket</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">1091</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">final_training_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">99.9</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">pocket_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">99.9</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">test_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">95.523</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">pocket_test_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">99.523</span>
</span></span></code></pre></div><p>Note that the relation between the training and testing accuracy values depends on how the test domain and number of test points are chosen. If the test set is scaled to maintain the same density of points (i.e. using the same scaling factor for number of points as for the dimensions of the subspace), as was done in the above code, the result will be as expected, i.e. the training accuracy will be higher than the testing accuracy.</p>
<p>However, if the test domain has a smaller density of points, the same line is likely to have many more correct classifications, thus making the test accuracy higher than the training accuracy. For instance, when the test domain was scaled to 1000 times the training domain, but the number of points increased only 100-fold, here were the results:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">i_pocket</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">1543</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">final_training_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">99.5</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">pocket_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span>  
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">99.7</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">test_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">99.991</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">pocket_test_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">99.976</span>
</span></span></code></pre></div><p>On the other hand, if the density of points is increased, i.e. the number of points is increased by a larger factor than the dimensions of the test domain, the training accuracy will always be higher, and the difference between the training accuracy and test accuracy becomes larger than in the case of same density. For instance, when the test domain was scaled to only 10 times the training domain, but the number of points increased 100-fold, here were the results:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">i_pocket</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">2000</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">final_training_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">99.8</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">pocket_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span>  
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">99.8</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">test_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">99.689</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;</span> <span class="nf">print</span><span class="p">(</span><span class="n">pocket_test_accuracy</span><span class="o">*</span><span class="m">100</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">[1]</span> <span class="m">99.689</span>
</span></span></code></pre></div><p>Of course, the exact same numbers will not be replicated since the code works with random values and no seed has been set. Clearly, plenty of experimentation can be done with different domains, different densities, different training and test sizes, and different initialization of <code>w</code>. The entire article has dealt with only two dimensions, but the same algorithms can be generalized to any number of dimensions, and will indeed prove useful where the data is known to be linearly separable. One of the best ways to learn about something from within is to build it from scratch. Having done that, perhaps one is now convinced that there is a lot more to the humble perceptron than one had earlier thought.</p>

    </article>
  

 

  

<div id="sharingbuttons">
    
    
    <a class="resp-sharing-button__link" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fwriteups%2fperceptron%2f" target="_blank" rel="noopener" aria-label="">
      <div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18.77 7.46H14.5v-1.9c0-.9.6-1.1 1-1.1h3V.5h-4.33C10.24.5 9.5 3.44 9.5 5.32v2.15h-3v4h3v12h5v-12h3.85l.42-4z"/></svg>
        </div>
      </div>
    </a>
    

    
    
    <a class="resp-sharing-button__link" href="https://twitter.com/intent/tweet/?text=Perceptrons%20from%20Scratch%3a%20A%20Starting%20Point%20for%20Machine%20Learning&amp;url=http%3a%2f%2flocalhost%3a1313%2fwriteups%2fperceptron%2f" target="_blank" rel="noopener" aria-label="">
      <div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M23.44 4.83c-.8.37-1.5.38-2.22.02.93-.56.98-.96 1.32-2.02-.88.52-1.86.9-2.9 1.1-.82-.88-2-1.43-3.3-1.43-2.5 0-4.55 2.04-4.55 4.54 0 .36.03.7.1 1.04-3.77-.2-7.12-2-9.36-4.75-.4.67-.6 1.45-.6 2.3 0 1.56.8 2.95 2 3.77-.74-.03-1.44-.23-2.05-.57v.06c0 2.2 1.56 4.03 3.64 4.44-.67.2-1.37.2-2.06.08.58 1.8 2.26 3.12 4.25 3.16C5.78 18.1 3.37 18.74 1 18.46c2 1.3 4.4 2.04 6.97 2.04 8.35 0 12.92-6.92 12.92-12.93 0-.2 0-.4-.02-.6.9-.63 1.96-1.22 2.56-2.14z"/></svg>
        </div>
      </div>
    </a>
    

    
    
    <a class="resp-sharing-button__link" href="mailto:?subject=Perceptrons%20from%20Scratch%3a%20A%20Starting%20Point%20for%20Machine%20Learning&amp;body=http%3a%2f%2flocalhost%3a1313%2fwriteups%2fperceptron%2f" target="_self" rel="noopener" aria-label="">
      <div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M22 4H2C.9 4 0 4.9 0 6v12c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zM7.25 14.43l-3.5 2c-.08.05-.17.07-.25.07-.17 0-.34-.1-.43-.25-.14-.24-.06-.55.18-.68l3.5-2c.24-.14.55-.06.68.18.14.24.06.55-.18.68zm4.75.07c-.1 0-.2-.03-.27-.08l-8.5-5.5c-.23-.15-.3-.46-.15-.7.15-.22.46-.3.7-.14L12 13.4l8.23-5.32c.23-.15.54-.08.7.15.14.23.07.54-.16.7l-8.5 5.5c-.08.04-.17.07-.27.07zm8.93 1.75c-.1.16-.26.25-.43.25-.08 0-.17-.02-.25-.07l-3.5-2c-.24-.13-.32-.44-.18-.68s.44-.32.68-.18l3.5 2c.24.13.32.44.18.68z"/></svg>
        </div>
      </div>
    </a>
    

    
    
    <a class="resp-sharing-button__link" href="https://www.linkedin.com/sharing/share-offsite/?url=http%3a%2f%2flocalhost%3a1313%2fwriteups%2fperceptron%2f" target="_blank" rel="noopener" aria-label="">
      <div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.5 21.5h-5v-13h5v13zM4 6.5C2.5 6.5 1.5 5.3 1.5 4s1-2.4 2.5-2.4c1.6 0 2.5 1 2.6 2.5 0 1.4-1 2.5-2.6 2.5zm11.5 6c-1 0-2 1-2 2v7h-5v-13h5V10s1.6-1.5 4-1.5c3 0 5 2.2 5 6.3v6.7h-5v-7c0-1-1-2-2-2z"/></svg>
        </div>
      </div>
    </a>
    

    
    
    <a class="resp-sharing-button__link" href="https://reddit.com/submit/?url=http%3a%2f%2flocalhost%3a1313%2fwriteups%2fperceptron%2f&amp;resubmit=true&amp;title=Perceptrons%20from%20Scratch%3a%20A%20Starting%20Point%20for%20Machine%20Learning" target="_blank" rel="noopener" aria-label="">
      <div class="resp-sharing-button resp-sharing-button--reddit resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M24 11.5c0-1.65-1.35-3-3-3-.96 0-1.86.48-2.42 1.24-1.64-1-3.75-1.64-6.07-1.72.08-1.1.4-3.05 1.52-3.7.72-.4 1.73-.24 3 .5C17.2 6.3 18.46 7.5 20 7.5c1.65 0 3-1.35 3-3s-1.35-3-3-3c-1.38 0-2.54.94-2.88 2.22-1.43-.72-2.64-.8-3.6-.25-1.64.94-1.95 3.47-2 4.55-2.33.08-4.45.7-6.1 1.72C4.86 8.98 3.96 8.5 3 8.5c-1.65 0-3 1.35-3 3 0 1.32.84 2.44 2.05 2.84-.03.22-.05.44-.05.66 0 3.86 4.5 7 10 7s10-3.14 10-7c0-.22-.02-.44-.05-.66 1.2-.4 2.05-1.54 2.05-2.84zM2.3 13.37C1.5 13.07 1 12.35 1 11.5c0-1.1.9-2 2-2 .64 0 1.22.32 1.6.82-1.1.85-1.92 1.9-2.3 3.05zm3.7.13c0-1.1.9-2 2-2s2 .9 2 2-.9 2-2 2-2-.9-2-2zm9.8 4.8c-1.08.63-2.42.96-3.8.96-1.4 0-2.74-.34-3.8-.95-.24-.13-.32-.44-.2-.68.15-.24.46-.32.7-.18 1.83 1.06 4.76 1.06 6.6 0 .23-.13.53-.05.67.2.14.23.06.54-.18.67zm.2-2.8c-1.1 0-2-.9-2-2s.9-2 2-2 2 .9 2 2-.9 2-2 2zm5.7-2.13c-.38-1.16-1.2-2.2-2.3-3.05.38-.5.97-.82 1.6-.82 1.1 0 2 .9 2 2 0 .84-.53 1.57-1.3 1.87z"/></svg>
        </div>
      </div>
    </a>
    

    
    
    <a class="resp-sharing-button__link" href="whatsapp://send?text=http%3a%2f%2flocalhost%3a1313%2fwriteups%2fperceptron%2f" target="_blank" rel="noopener" aria-label="">
      <div class="resp-sharing-button resp-sharing-button--whatsapp resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.1 3.9C17.9 1.7 15 .5 12 .5 5.8.5.7 5.6.7 11.9c0 2 .5 3.9 1.5 5.6L.6 23.4l6-1.6c1.6.9 3.5 1.3 5.4 1.3 6.3 0 11.4-5.1 11.4-11.4-.1-2.8-1.2-5.7-3.3-7.8zM12 21.4c-1.7 0-3.3-.5-4.8-1.3l-.4-.2-3.5 1 1-3.4L4 17c-1-1.5-1.4-3.2-1.4-5.1 0-5.2 4.2-9.4 9.4-9.4 2.5 0 4.9 1 6.7 2.8 1.8 1.8 2.8 4.2 2.8 6.7-.1 5.2-4.3 9.4-9.5 9.4zm5.1-7.1c-.3-.1-1.7-.9-1.9-1-.3-.1-.5-.1-.7.1-.2.3-.8 1-.9 1.1-.2.2-.3.2-.6.1s-1.2-.5-2.3-1.4c-.9-.8-1.4-1.7-1.6-2-.2-.3 0-.5.1-.6s.3-.3.4-.5c.2-.1.3-.3.4-.5.1-.2 0-.4 0-.5C10 9 9.3 7.6 9 7c-.1-.4-.4-.3-.5-.3h-.6s-.4.1-.7.3c-.3.3-1 1-1 2.4s1 2.8 1.1 3c.1.2 2 3.1 4.9 4.3.7.3 1.2.5 1.6.6.7.2 1.3.2 1.8.1.6-.1 1.7-.7 1.9-1.3.2-.7.2-1.2.2-1.3-.1-.3-.3-.4-.6-.5z"/></svg>
        </div>
      </div>
    </a>
    

    
    
    <a class="resp-sharing-button__link" href="https://news.ycombinator.com/submitlink?u=http%3a%2f%2flocalhost%3a1313%2fwriteups%2fperceptron%2f&amp;t=Perceptrons%20from%20Scratch%3a%20A%20Starting%20Point%20for%20Machine%20Learning" target="_blank" rel="noopener" aria-label="">
      <div class="resp-sharing-button resp-sharing-button--hackernews resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
    	<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 140 140"><path fill-rule="evenodd" d="M60.94 82.314L17 0h20.08l25.85 52.093c.397.927.86 1.888 1.39 2.883.53.994.995 2.02 1.393 3.08.265.4.463.764.596 1.095.13.334.262.63.395.898.662 1.325 1.26 2.618 1.79 3.877.53 1.26.993 2.42 1.39 3.48 1.06-2.254 2.22-4.673 3.48-7.258 1.26-2.585 2.552-5.27 3.877-8.052L103.49 0h18.69L77.84 83.308v53.087h-16.9v-54.08z"></path></svg>
        </div>
      </div>
    </a>
    

    
    
    <a class="resp-sharing-button__link" href="https://telegram.me/share/url?text=Perceptrons%20from%20Scratch%3a%20A%20Starting%20Point%20for%20Machine%20Learning&amp;url=http%3a%2f%2flocalhost%3a1313%2fwriteups%2fperceptron%2f" target="_blank" rel="noopener" aria-label="">
      <div class="resp-sharing-button resp-sharing-button--telegram resp-sharing-button--small"><div aria-hidden="true" class="resp-sharing-button__icon resp-sharing-button__icon--solid">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M.707 8.475C.275 8.64 0 9.508 0 9.508s.284.867.718 1.03l5.09 1.897 1.986 6.38a1.102 1.102 0 0 0 1.75.527l2.96-2.41a.405.405 0 0 1 .494-.013l5.34 3.87a1.1 1.1 0 0 0 1.046.135 1.1 1.1 0 0 0 .682-.803l3.91-18.795A1.102 1.102 0 0 0 22.5.075L.706 8.475z"/></svg>
        </div>
      </div>
    </a>
    
</div>

  <div class="paginator">
    
      <a class="link" href="http://localhost:1313/writeups/rice/">← prev</a>
    
    
      <a class="link" href="http://localhost:1313/writeups/flowers/">next →</a>
    
  </div>

  

</main>

    <footer id="footer">
  <div>
    <span>Powered by  <a class=link href=https://gohugo.io target=_blank rel=noopener>Hugo</a> |  Customized from the <a class=link href=https://github.com/michaelneuper/hugo-texify3 target=_blank rel=noopener>TeXify3</a>
theme</span>
  </div>
  <div>
    <span>Copyright © 2025 Simran Tinani </span>
  </div>

  <script>
    document.addEventListener("DOMContentLoaded", function () {
      const sections = document.querySelectorAll("h2[id]");
      const navLinks = document.querySelectorAll(".category-scroll-nav a");
    
      function activateLink() {
        let scrollY = window.scrollY + 100;
    
        sections.forEach(section => {
          const id = section.getAttribute("id");
          const top = section.offsetTop;
    
          if (scrollY >= top) {
            navLinks.forEach(link => {
              link.classList.remove("active");
              if (link.getAttribute("href") === `#${id}`) {
                link.classList.add("active");
              }
            });
          }
        });
      }
    
      window.addEventListener("scroll", activateLink);
    });
    </script>
    
</footer>

  </div>

  
  <script src='http://localhost:1313/js/script.js' defer></script>

  
  

  
  

  
  

</body>

</html>
